{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2427e3eb",
   "metadata": {},
   "source": [
    "# Imbalanced Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d800a",
   "metadata": {},
   "source": [
    "If you are classifying data, and the classes are not relatively balanced in size, the bias toward more popular classes can carry over into your model. For example, if you have 1 positive case and 99 negative cases, you can get 99% accuracy by simply classifying everything as negative. There are various options for dealing with _imbalanced classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a27cfd",
   "metadata": {},
   "source": [
    "## Use a different metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b8dfbd",
   "metadata": {},
   "source": [
    "One hint is to use a measure other than accuracy (AUC is a good choice) for calibrating models. Precision and recall are also better options when the target sizes are different. However, there are other options to consider as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f206e12",
   "metadata": {},
   "source": [
    "## Tree-based Algorithms and Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835208ed",
   "metadata": {},
   "source": [
    "Tree-based models may perform better depending on the distribution of the smaller class. If they tend to be clustered, they can be classified easier. \n",
    "\n",
    "Ensamble methods can further aid in pulling out the minority classes. Bagging and boosting are options found in tree models like random forest and Extreme Gradient Boosting (XGBoost)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f02af",
   "metadata": {},
   "source": [
    "## Penalize Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a369c",
   "metadata": {},
   "source": [
    "Many scikit-learn classification models support the `class_weight` parameter. Setting this to `balanced` will attempt to regularize minority classes and incetivize the model to classify them correctly. Alternatively, you can grid search and specify the weight options by passing in a dictionary mapping class to  weight (give higher weight to smaller classes).\n",
    "\n",
    "The XGBoost library has the `max_delta_step` parameter, which can b set from 1 to 10 to make the update step more conservative. It also has the `scale_pos_weight` parameter that sets the ratio of negative to positive samples (for binary classes). Also, the `eval_metric` should be set to `'auc'` rather than the default value of `'error'` for classification. \n",
    "\n",
    "The KNN model has a `weights` parameter that can bias neighbor that are closer. If the minority class samples are close together, setting this parameter to `distance` may improve performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb155c",
   "metadata": {},
   "source": [
    "## Upsampling Minority"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d416754",
   "metadata": {},
   "source": [
    "You can upsample the minority class in a couple of ways. Here is an sklearn implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36410ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7bcfee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e72245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('df.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "506b31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c639c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.survived == 1\n",
    "surv_df = df[mask]\n",
    "death_df = df[-mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9292cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsample = resample(surv_df, replace= True, n_samples = len(death_df), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8feec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([death_df, df_upsample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09fc7a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    809\n",
       "1    809\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9aef1",
   "metadata": {},
   "source": [
    "We can also use the imbalanced-learn library to randomly sample with replacement: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe9e1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\alber\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\alber\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\alber\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\alber\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alber\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.2.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.8.1 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "#! pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6f2a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import (RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1873c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3cfe336",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_excel('X.xls')\n",
    "y = pd.read_excel('y.xls')\n",
    "X.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "y.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96e127f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0           809\n",
       "1           809\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ros, y_ros = ros.fit_resample(X,y)\n",
    "y_ros.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbfecd",
   "metadata": {},
   "source": [
    "## Generate Minority Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a2c75",
   "metadata": {},
   "source": [
    "The imbalanced-learn library can also generate new samples of minority classes with both the Synthetic Minority OverSampling Technique (SMOTE) and Adaptive Synthetic (ADASYN) sampling approach algorithms. SMOTE works by choosing one of its k-nearest-neighbors, connecting a line to one of them, and choosing a point along that line. ADASYN is similar to SMOTE, but generates more smaple from those that are harder to learn. The classes in imbanced-learn are named `over_sampling.SMOTE` and `over_sampling.ADASYN`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f0efc",
   "metadata": {},
   "source": [
    "## DownSampling Majority "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0d50f",
   "metadata": {},
   "source": [
    "Another method to balance classes is to downsample majority classes. Here is an sklearn example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "686c0dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c6dd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.survived == 1\n",
    "surv_df = df[mask]\n",
    "death_df = df[-mask]\n",
    "df_downsample = resample(death_df, replace = False, n_samples=len(surv_df), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d37a419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([surv_df, df_downsample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5743b579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4c75b",
   "metadata": {},
   "source": [
    "__TIP__ : Do not use replacement when downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deae019",
   "metadata": {},
   "source": [
    "The imbalanced-learn library also implements various downsampling algorithms: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd03279",
   "metadata": {},
   "source": [
    "* `ClusterCentroids` -> This class uses K-means to synthesize data with the centroids\n",
    "* `RandomUnderSampler` -> This class randomly selects samples\n",
    "* `NearMiss` -> This class uses nearest neighbors to downsample\n",
    "* `TomekLink` -> This class downsamples by removing samples that are cloe to each other\n",
    "* `EditedNearestNeighbours` -> This class removes samples that have neighbors that are either not in the majority or all of the same class.\n",
    "* `RepeatedNearestNeighbours` -> This class repeatedly calls `EditedNearestNeighbours` \n",
    "* `AllKNN` -> This class is similar but increases the number of nearest neighbors during the iteration of downsampling.\n",
    "* `CondensedNearestNeighbour` -> This class picks one sample of the class to be downsampled, then iterates through the other samples of the class, and if KNN does not missclassify, it adds that sample. \n",
    "* `OneSidedSelection` -> This class removes noisy samples. \n",
    "* `NeighbourhoodCleaningRule` -> This class uses `EditedNearestNeighbours` results and applies KNN to it. \n",
    "* `InstanceHardnessThreshold` -> This class trains a model, then removes samples with low probabilities.\n",
    "\n",
    "All of these classes support the `.fit_sample` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1135ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
